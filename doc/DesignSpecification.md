Ax/Wx - Traffic Accident / Weather Analysis - Design Specification
==================================================================


COMPONENTS
----------
_This section lists the components that we expect to have in our project (not necessarily a complete list), what they do, and how they interface (e.g., functions with inputs and outputs). This includes documentation for existing packages. For the components we have or plan to implement, we have listed the inputs and outputs._

#### Retrieve Personal Weather Station (PWS) Information

We use a function called `scrape_station_info` to retrieve information about Personal Weather Stations within a single state. The following is an example source URL for Washington state:
https://www.wunderground.com/weatherstation/ListStations.asp?selectedState=WA&selectedCountry=United+States&MR=1

For each station in a given state, we scrape the Station ID, Neighborhood, City and Station Type. This function uses the `requests` and `BeautifulSoup` packages to scrape the station information and outputs station information as a `numpy` array.

The function runs as follows:

- Retrieves HTML of station data table for the requested state
- Parses out table rows as elements in a list
- Splits strings for each element in the station info list
- Adds each row's data as a new row in a `numpy` array

#### Getting the Latitude and Longitude from the Weather Stations

Use the data scraped previously from Weather Underground (WU) listing the unique station identification. From this data, we created a script to obtain the latitude and longitude from the weather stations. The script runs as follows:

- Load the data into python using a `pandas` DataFrame
- For each StationID:
    - Use `urllib3` package to make each API request using StationID
    - Use `BeautifulSoup` to parse the XML document for latitude, longitude and elevation
    - Any missing data was filled in with NA's
- Save the file and move on to bigger things

#### WU Personal Weather Station Observation Data Retrieval

For this component, we use two functions: `scrape_data_one_day` retrieves data from a single weather station for a single day and outputs the data as a `pandas` DataFrame. The function uses the `requests` and `BeautifulSoup` packages. A second function - `scrape_data_multi_day` - acts as a wrapper around the `scrape_data_one_day` function, returning a `pandas` DataFrame with observation data from a single station over a range of dates. We will run the `scrape_data_multi_day` function over the list of personal weather stations generated by the PWS list component described above.

#### WU Personal Weather Station Observation Cleanup

For this component, we will use a function that takes a `pandas` DataFrame from the WU PWS Observation Data Retrieval a single station and cleans it according to various issues identified in the data. The script will also include an aggregation component to reduce the size of the project's weather database.

#### Collision Data - Washington State Patrol (WSP) Collision Analysis Tool (CAT)
https://fortress.wa.gov/wsp/collisionanalysistool

The CAT provides the means to pull collision data that will be utilized in the project. This data can be pulled any time, with any filters (e.g., data ranges, cities, or counties) and can then be passed through the collision data cleanup. The data is provided by the WSP which keeps a detailed database of all reported collisions in Washington State. 

#### Collision Data Cleanup

The raw data includes several attributes that were not pertinent to the original scope of the project and Ax/Wx analysis (217 attributes total). The purpose of the collision data cleanup is to get the data in such a format that it can be merged with the WU data and overlaid onto a map and several visualizations. To merge the two datasets, a function has been designed to transform the current WSP coordinate system (input) to global latitudes and longitudes (output). These new coordinates, along with dates and times, will be used to merge the collision data with the weather data.

#### Merge of Collision Data and Weather Data

Using the coordinate mapping for the collision data, the plan is to design a function that takes the latitudes and longitudes as input and finds the nearest weather station information from the weather data. The weather data will be appended to the collision data, providing a new data file that is ready for the visualization process.

#### Visualization of Data

The visualization will consist of several plots of the collision/weather data. These visuals serve as templates for further analysis that can be done using Ax/Wx. The example visualization includes the following:

- A primary visualization of a city map of Seattle with collisions marked by blue dots
- Breakdown of contributing factors of collisions by rainfall
- Exploratory bar charts of how particular weather data relates to the number of collisions
- Comparison between the subjective classification of road conditions versus the objective weather data of the nearest PWS (with 3 miles)

The Python packages that will be utilized for the visualization are listed as follows:

- `bokeh` - http://bokeh.pydata.org/en/latest/docs/dev_guide/documentation.html
	- The package `bokeh` is an interactive visualization library to help aid presentation by use of advanced custom graphics (such as interactive plots, dashboards, and data applications) in the style of D3.js.


INTERACTIONS
------------

Most of the components listed above are preliminary steps required to get the data in such a format that it can easily be viewed by users. The culmination of the data retrieval and cleaning process is a single database of collision data with associated weather data; this database can be used for more in-depth analysis into the relationship between collisions and weather in the greater Seattle area.

The analysis tool itself focuses on scraping, cleaning and merging the two data sets so that they can easily be visualized for analysis. Specific user-based interactions are briefly described below.

#### Traffic Engineer

Recently in Seattle, traffic engineers have implemented “variable speed zones” on I-5 based on traffic patterns. A traffic engineer could use the Ax/Wx analysis tool to answer questions such as where more “variable speed zones” should be implemented, and when the speed should be adjusted (i.e. collisions occur X% more often at location Y when the weather conditions are Z).

#### Law Enforcement Officer

A law enforcement officer could look at the weather report prior to planning his or her shift, and subsequently use the Ax/Wx tool to determine where collisions are more likely to occur given the current weather (predictive analysis based on past conditions). Providing an increased law enforcement presence in those specific locations may reduce collisions.

#### Insurance Company

With Ax/Wx, an individual working for an insurance company could determine whether an insured driver drives frequently in areas known to have an increased risk of collisions due to inclement weather conditions. Alternatively, they could also use Ax/Wx to reduce premiums for drivers that drive more often in fair weather or along roadways that are not significantly impacted by weather conditions.

#### Common Driver

Ax/Wx could provide drivers with the best route possible for avoiding traffic collisions (based on historical data), given the current weather conditions. Further uses could include increasing the detail provided by an existing application such as Google Maps. Through Ax/Wx analysis, more data could be leveraged by Google Maps to allow the common driver to know "safer routes" given the current weather conditions.


PROJECT PLAN
------------
_Note: This project plan outlines the original plan at the time this document was created._

Week 1:

- latitude/longitude station data table
- weather data scraping
- data cleaning
	- weather
	- collision
- data Merging
- data Visualization Skeleton
- package selection for maps

Week 2:

- data package creation
- data visualization development
- data integrity checks (quality control)
- code quality and commenting - `PEP8`, `PyLint`

Week 3:

- unit testing
- update specifications and documentation
	 - functional specification
	 - design specification
	 - `README.md`
	 - `LICENSE`
- project structure checks
	- `Setup.py` file
	- doc folder
	- python package folder
	- python modules
- project examples
- data poster
- oral presentation practice runs
